{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/21 11:32:38 WARN Utils: Your hostname, mahesh-Aspire-A315-59 resolves to a loopback address: 127.0.1.1; using 192.168.1.42 instead (on interface wlp43s0)\n",
      "25/05/21 11:32:38 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/21 11:32:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext(\"local\",\"lab_1_mapreduce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Word Count with Filtering**\n",
    "**Input:** A file named `documents.txt`, each line containing a sentence.  \n",
    "**Task:** Write PySpark code to:\n",
    "- Count the frequency of each word (case-insensitive).\n",
    "- Exclude stopwords like `[\"a\", \"the\", \"is\", \"in\", \"at\", \"on\", \"and\"]`.\n",
    "- Output should be sorted by frequency in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = sc.textFile(\"..//lab_datasets/documents.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = docs.flatMap(lambda line: line.strip().split(\"\\t\")[1].split(\" \"))\\\n",
    "    .filter(lambda word: word.lower() not in [\"a\", \"the\", \"is\", \"in\", \"at\", \"on\", \"and\"])\\\n",
    "        .map(lambda word: (word, 1))\\\n",
    "            .reduceByKey(lambda a, b: a + b)\\\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"word_count_with_filtering.txt\", \"w\") as f:\n",
    "    contents.saveAsTextFile(\"word_count_with_filtering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Most Purchased Product**\n",
    "**Input:** A CSV file `transactions.csv` in the format: `user_id,product_id,timestamp`.  \n",
    "**Task:** \n",
    "- Find the product(s) with the highest number of purchases.\n",
    "- Save the result as: `(\"product_id\", count)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = sc.textFile(\"../lab_datasets/transactions.csv\")\n",
    "sorted_counts =  docs.map(lambda line: line.strip().split(\",\"))\\\n",
    "    .map(lambda fields: (fields[1], 1))\\\n",
    "        .reduceByKey(lambda a, b: a + b)\\\n",
    "            .sortBy(lambda x: x[1], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the highest purchase count\n",
    "# get the first element\n",
    "product, count = sorted_counts.take(1)[0]\n",
    "\n",
    "sorted_counts.filter(lambda x: x[1] == count)\\\n",
    "    .saveAsTextFile('highest_purchase_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Average Rating Per Product**\n",
    "**Input:** A CSV file `reviews.csv` in the format: `user_id,product_id,rating`.  \n",
    "**Task:** \n",
    "- Compute the **average rating** for each product.\n",
    "- Output format: `(\"product_id\", average_rating)` rounded to 2 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = sc.textFile(\"../lab_datasets/reviews.csv\")\n",
    "#remove the output dir and files if it already exists\n",
    "\n",
    "#delete a directory if it already exists including all files in the directory\n",
    "if os.path.exists(\"average_rating_per_product\"):\n",
    "    shutil.rmtree(\"average_rating_per_product\")\n",
    "    \n",
    "docs.map(lambda line: line.strip().split(\",\"))\\\n",
    "    .map(lambda fields: (fields[1], int(fields[2])))\\\n",
    "        .reduceByKey(lambda a, b: a*0.5 + b*0.5)\\\n",
    "            .sortByKey(ascending=True)\\\n",
    "                .saveAsTextFile('average_rating_per_product')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5. Most Active User by Reviews**\n",
    "**Input:** Same as above (`reviews.csv`).  \n",
    "**Task:** \n",
    "- Identify the user(s) who submitted the **highest number of reviews**.\n",
    "- Output format: `(\"user_id\", review_count)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = sc.textFile(\"../lab_datasets/reviews.csv\")\n",
    "\n",
    "sorted_user_review_counts = docs.map(lambda line: line.strip().split(\",\"))\\\n",
    "    .map(lambda fields: (fields[0], 1))\\\n",
    "        .reduceByKey(lambda a, b: a + b)\\\n",
    "            .sortBy(lambda x: x[1], ascending=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "user, num_reviews = sorted_user_review_counts.take(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"highest_review_count\"):\n",
    "    shutil.rmtree(\"highest_review_count\")\n",
    "    \n",
    "sorted_user_review_counts.filter(lambda x: x[1] == num_reviews)\\\n",
    "    .saveAsTextFile('highest_review_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
